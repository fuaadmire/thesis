# -*- coding: utf-8 -*-
"""binary_version_lstm_pretrained_emb_timedistributed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HZn3lylIMBOUzWG8uSTclphUl_pqgSOh
"""

#!git clone https://terne:Sofus2860@github.com/terne/thesis.git

from keras.preprocessing import sequence
from keras.layers import Embedding, Input, Dense, LSTM, TimeDistributed, Dropout, CuDNNLSTM
from keras.models import Model
from thesis.preprocess_text import preprocess
from keras.utils import multi_gpu_model # for data parallelism
from keras.constraints import NonNeg
from keras import regularizers
from keras.utils import plot_model
from keras.utils.np_utils import to_categorical
import numpy as np
import codecs
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.metrics import f1_score
import pandas as pd
import h5py
import nltk
#import matplotlib.pyplot as plt
import datetime
from thesis.write_dict_file import d_write
import nltk
nltk.download('punkt')
import gensim
#from thesis.get_liar_binary_data import *
import random

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle

random.seed(16)
np.random.seed(16)

def binarize_labels(labels):
    labels_transformed = [1 if i in [2,3,5] else 0 for i in labels]
    return labels_transformed

def load_liar_data(path):

    liar_train = codecs.open(path+"data/liar_xtrain.txt", 'r', 'utf-8').read().split('\n')
    liar_train = [s.lower() for s in liar_train if len(s) > 1]
    liar_train_labels = codecs.open(path+'data/liar_ytrain.txt', 'r', 'utf-8').read().split('\n')
    liar_train_lab = [s for s in liar_train_labels if len(s) > 1]

    liar_dev = codecs.open(path+"data/liar_xval.txt", 'r', 'utf-8').read().split('\n')
    liar_dev = [s.lower() for s in liar_dev if len(s) > 1]
    liar_dev_labels = codecs.open(path+"data/liar_yval.txt", 'r', 'utf-8').read().split('\n')
    liar_dev_lab = [s for s in liar_dev_labels if len(s) > 1]

    liar_test = codecs.open(path+"data/liar_xtest.txt", 'r', 'utf-8').read().split('\n')
    liar_test = [s.lower() for s in liar_test if len(s) > 1]
    liar_test_labels = codecs.open(path+"data/liar_ytest.txt", 'r', 'utf-8').read().split('\n')
    liar_test_lab = [s for s in liar_test_labels if len(s) > 1]

    assert len(liar_train) == len(liar_train_lab)
    assert len(liar_dev) == len(liar_dev_lab)
    assert len(liar_test) == len(liar_test_lab)

    le = preprocessing.LabelEncoder()
    #classes = ['pants-fire','false','barely-true','half-true','mostly-true','true']
    #le.fit_transform(classes)
    liar_train_lab = le.fit_transform(liar_train_lab)
    liar_dev_lab = le.transform(liar_dev_lab)
    liar_test_lab = le.transform(liar_test_lab)

    print(le.classes_) #['barely-true' 'false' 'half-true' 'mostly-true' 'pants-fire' 'true']
    print(le.transform(le.classes_)) # [0 1 2 3 4 5]
    # untrue classes (to be encoded as 0): 4, 1, 0
    # true classes (to be encoded as 1): 2, 3, 5

    liar_train_lab = binarize_labels(liar_train_lab)
    liar_dev_lab = binarize_labels(liar_dev_lab)
    liar_test_lab = binarize_labels(liar_test_lab)

    return liar_train, liar_dev, liar_test, liar_train_lab, liar_dev_lab, liar_test_lab

from google.colab import drive
drive.mount('/gdrive')

liar_train, liar_dev, liar_test, train_lab, dev_lab, test_lab = load_liar_data("thesis/")

# disregarding input which is less than 100 characters (as they do not contain many words, if any)
#labels_include = []
#data_include = []
#for indel, i in enumerate(data):
#    if len(i) > 100:
#        data_include.append(i)
#        labels_include.append(labels[indel])


#train, dev, train_lab, dev_lab = train_test_split(data_include, labels_include, test_size=0.33, random_state=42)

#preprocessing is going wrong. returns letters instead of words :)
#train = preprocess(train)
#dev = preprocess(dev)

train = [nltk.word_tokenize(i.lower()) for i in liar_train]
dev = [nltk.word_tokenize(i.lower()) for i in liar_dev]
test = [nltk.word_tokenize(i.lower()) for i in liar_test]

# perhaps edit this to make dict straight away.

all_train_tokens = []
for i in train:
    for word in i:
        all_train_tokens.append(word)

vocab = set(all_train_tokens)
word2id = {word: i+1 for i, word in enumerate(vocab)}# making the first id is 1, so that I can pad with zeroes.
word2id["UNK"] = len(word2id)+1
id2word = {v: k for k, v in word2id.items()}

#trainTextsSeq: List of input sequence for each document (A matrix with size num_samples * max_doc_length)
trainTextsSeq = np.array([[word2id[w] for w in sent] for sent in train])
devTextsSeq = np.array([[word2id.get(w, word2id["UNK"]) for w in sent] for sent in dev])
testTextsSeq = np.array([[word2id.get(w, word2id["UNK"]) for w in sent] for sent in test])

# PARAMETERS
# vocab_size: number of tokens in vocabulary
vocab_size = len(word2id)+1
# max_doc_length: length of documents after padding (in Keras, the length of documents are usually padded to be of the same size)
max_doc_length = 100 # LIAR 100 (like Wang), Kaggle 3391, FakeNewsCorpus 2669
# num_cells: number of LSTM cells
num_cells = 64 # for now, probably test best parameter through cross-validation
# num_samples: number of training/testing data samples
num_samples = len(train_lab)
# num_time_steps: number of time steps in LSTM cells, usually equals to the size of input, i.e., max_doc_length
num_time_steps = max_doc_length
embedding_size = 300 # also just for now..
num_epochs = 10
num_batch = 64 # also find optimal through cross-validation


# PREPARING DATA

# padding with max doc lentgh
seq = sequence.pad_sequences(trainTextsSeq, maxlen=max_doc_length, dtype='int32', padding='post', truncating='post', value=0.0)
print("train seq shape",seq.shape)
dev_seq = sequence.pad_sequences(devTextsSeq, maxlen=max_doc_length, dtype='int32', padding='post', truncating='post', value=0.0)
test_seq = sequence.pad_sequences(testTextsSeq, maxlen=max_doc_length, dtype='int32', padding='post', truncating='post', value=0.0)

# Reshape y_train:
def tile_reshape(train_lab, num_time_steps):
    y_train_tiled = np.tile(train_lab, (num_time_steps,1)).T
    y_train_tiled = y_train_tiled.reshape(len(train_lab), num_time_steps , 1)
    #print("y_train_shape:",y_train_tiled.shape)
    return y_train_tiled

y_train_tiled = tile_reshape(train_lab, num_time_steps)
y_dev_tiled = tile_reshape(dev_lab, num_time_steps)
y_test_tiled = tile_reshape(test_lab, num_time_steps)

print("Parameters:: num_cells: "+str(num_cells)+" num_samples: "+str(num_samples)+" embedding_size: "+str(embedding_size)+" epochs: "+str(num_epochs)+" batch_size: "+str(num_batch))
print(y_train_tiled.shape)

# https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html

# Load Google's pre-trained Word2Vec model.
model = gensim.models.KeyedVectors.load_word2vec_format('/gdrive/My Drive/Thesis/GoogleNews-vectors-negative300.bin', binary=True)

embedding_matrix = np.zeros((len(word2id) + 1, 300))
for word, i in word2id.items():
    try:
        embedding_vector = model.wv[word]
    except:
        embedding_vector = model.wv["UNK"]
    if embedding_vector is not None:
        embedding_matrix[i] = embedding_vector

myInput = Input(shape=(max_doc_length,), name='input')
print(myInput.shape)
# use pretrained embeddings:
x = Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[embedding_matrix],input_length=max_doc_length,trainable=True)(myInput)
#x = Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_doc_length)(myInput)
print(x.shape)
#lstm_out = CuDNNLSTM(num_cells, return_sequences=True, kernel_constraint=NonNeg())(x)
lstm_out = LSTM(num_cells, dropout=0.8, recurrent_dropout=0.8, return_sequences=True, kernel_constraint=NonNeg())(x)
print(lstm_out.shape)
#out = TimeDistributed(Dense(2, activation='softmax'))(lstm_out)
predictions = TimeDistributed(Dense(1, activation='sigmoid', kernel_constraint=NonNeg()))(lstm_out) #kernel_constraint=NonNeg()

print("predictions_shape:",predictions.shape)
model = Model(inputs=myInput, outputs=predictions)


# try-except to switch between gpu and cpu version
#try:
#    parallel_model = multi_gpu_model(model, gpus=2)
#    parallel_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
#    print("fitting model..")
#    parallel_model.fit({'input': seq}, y_train_tiled, epochs=num_epochs, verbose=2, batch_size=num_batch, validation_split=.20)
#    print("Testing...")
#    score = parallel_model.evaluate(test_seq, y_test_tiled, batch_size=num_batch, verbose=0)
#    print("Test loss:", score[0])
#    print("Test accuracy:", score[1])
    # get predicted classes
#    train_preds = model.predict(seq)
#    test_preds = model.predict(test_seq)
#except:


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
print("fitting model..")
model.fit({'input': seq}, y_train_tiled, epochs=num_epochs, verbose=2, batch_size=num_batch, validation_data=(dev_seq,y_dev_tiled))
print("Testing...")
dev_score = model.evaluate(dev_seq, y_dev_tiled, batch_size=num_batch, verbose=0)
test_score = model.evaluate(test_seq, y_test_tiled, batch_size=num_batch, verbose=0)
print("Valid loss:", dev_score[0])
print("Valid accuracy:", dev_score[1])
print("Test loss:", test_score[0])
print("Test accuracy:", test_score[1])

model.summary()

from keras.models import load_model
model.save('LIAR_model.h5')

model.save_weights('LIAR_weights.h5')

# Save plot of model
plot_model(model, to_file="model.png")

# Getting all the files

# text files
trainTextsSeq_flatten = np.array(seq).flatten()
hf = h5py.File("train.hdf5", "w") # need this file for LSTMVis
hf.create_dataset('words', data=trainTextsSeq_flatten)
hf.close()

testTextsSeq_flatten = np.array(test_seq).flatten()
hf_t = h5py.File("test.hdf5", "w") # need this file for LSTMVis
hf_t.create_dataset('words', data=testTextsSeq_flatten)
hf_t.close()



# predictions

# get predicted classes
train_preds = model.predict(seq)
test_preds = model.predict(test_seq)

# if multiclass:
#y_classes_train = train_preds.argmax(axis=-1)
#y_classes_test = test_preds.argmax(axis=-1)
# if binary:
#y_classes = (y_prob > 0.5).astype(np.int)
y_classes_train = (train_preds > 0.5).astype(np.int)
y_classes_test = (test_preds > 0.5).astype(np.int)

# save predicted classes!
predicted_train_classes_flatten = np.array(y_classes_train).flatten()
hf_p = h5py.File("predictions.hdf5", "w")
hf_p.create_dataset('preds_train', data=predicted_train_classes_flatten)
#hf_p.close()
predicted_test_classes_flatten = np.array(y_classes_test).flatten()
hf_p.create_dataset('preds_test', data=predicted_test_classes_flatten)
#hf_pt = h5py.File("test_predictions.hdf5", "w")
#hf_pt.create_dataset('preds', data=predicted_test_classes_flatten)
test_true_classes = np.array(y_test_tiled).flatten()
hf_p.create_dataset('true_classes_testset', data=test_true_classes)
train_true_classes = np.array(y_train_tiled).flatten()
hf_p.create_dataset('true_classes_trainset', data=train_true_classes)
hf_p.close()

# dictionary
d_write("words.dict", word2id)
d_write("words.dict", {"PADDING": 0}) # add padding token to lstmvis dict

# states
model.layers.pop();
inp = model.inputs
out = model.layers[-1].output
model_RetreiveStates = Model(inp, out)

states_model = model_RetreiveStates.predict(seq, batch_size=num_batch)
states_model_flatten = states_model.reshape(num_samples * num_time_steps, num_cells)# Flatten first and second dimension for LSTMVis
hf = h5py.File("states.hdf5", "w")
hf.create_dataset('states_train', data=states_model_flatten)
#hf.close()

# solved
states_model_test = model_RetreiveStates.predict(test_seq, batch_size=num_batch)
states_model_test_flatten = states_model_test.reshape(len(test_seq) * num_time_steps, num_cells)# Flatten first and second dimension for LSTMVis
hf.create_dataset('states_test', data=states_model_test_flatten)
hf.close()
